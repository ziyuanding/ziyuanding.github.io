<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content="width=device-width"><title>有没有必要手动安装CUDA |</title><link rel=stylesheet href=https://ziyuanding.github.io/css/main.min.ae047bae72f7cfdc69dab3d0757b51bb79c4c867ba9a336983ec0c2a20c576eb.css integrity="sha256-rgR7rnL3z9xp2rPQdXtRu3nEyGe6mjNpg+wMKiDFdus="><link rel=stylesheet href=https://ziyuanding.github.io/semantic/dist/semantic.min.css><link rel=stylesheet href=https://ziyuanding.github.io/css/vendor/syntax.css><script src=https://code.jquery.com/jquery-2.2.2.min.js integrity="sha256-36cp2Co+/62rEAAYHLmRCPIych47CvdM+uTBJwSzWjI=" crossorigin=anonymous></script><script src=/semantic/dist/semantic.min.js></script><script src=/js/vendor/fontawesome-all.js></script></head><body><header><nav><div class="ui grid container"><div class="computer only row"><div class="ui fluid large borderless blue menu"><div class="fitted item"><a href=/ style=text-decoration:none;color:#000><b>DING</b></a></div><div class=item><div class=item style=position:relative><div class="ui fluid transparent icon input"><input id=search-box type=text placeholder="Search posts...">
<i class="search icon"></i></div><ul id=search-results></ul></div></div><div class="right menu"><div class="ui item"><a href=/about style=text-decoration:none;color:#000><b>ABOUT</b></a></div><div class="ui item" style=padding-left:5px!important;padding-right:5px!important><a href=https://www.linkedin.com/in/ziyuan-ding-467314249/ target=_blank style=text-decoration:none;color:#000><i class="linkedin icon"></i></a></div><div class="ui item" style=padding-left:5px!important;padding-right:5px!important><a href=https://github.com/ziyuanding target=_blank style=text-decoration:none;color:#000><i class="github icon"></i></a></div></div></div></div><div class="tablet only row"><div class="ui fluid large borderless blue menu"><div class="fitted item"><a href=/ style=text-decoration:none;color:#000><b>DING</b></a></div><div class=item><div class=item style=position:relative><div class="ui fluid transparent icon input"><input id=search-box type=text placeholder="Search posts...">
<i class="search icon"></i></div><ul id=search-results></ul></div></div></div></div><div class="mobile only row"><div class="ui fluid borderless blue menu xo marginless"><div class="fitted item"><a href=/ style=text-decoration:none;color:#000><b>DING</b></a></div></div><div class="ui fluid borderless menu xo marginless center aligned"><div class=item><div class=item style=position:relative><div class="ui fluid transparent icon input"><input id=search-box type=text placeholder="Search posts...">
<i class="search icon"></i></div><ul id=search-results></ul></div></div></div></div></div></nav><style>#search-box{position:relative;z-index:10}#search-results{position:absolute;top:100%;left:0;width:100%;background:#fff;border:1px solid #ccc;border-top:none;max-height:250px;overflow-y:auto;box-shadow:0 2px 8px rgba(0,0,0,.1);z-index:9999;display:none;list-style:none;padding:0;margin:0}#search-results.show{display:block}#search-results li{padding:8px 12px;cursor:pointer}#search-results li:hover{background:#f0f0f0}</style><script src=https://cdn.jsdelivr.net/npm/fuse.js@6.6.2></script><script>async function searchPosts(e){const t=document.getElementById("search-results");if(!e.trim()){t.innerHTML="",t.classList.remove("show");return}const s=await fetch("/index.json"),o=await s.json(),i=new Fuse(o,{keys:["title","content"],threshold:.3}),n=i.search(e);t.innerHTML=n.map(e=>`<li><a href="${e.item.url}">${e.item.title}</a></li>`).join(""),n.length>0?t.classList.add("show"):t.classList.remove("show")}const searchBox=document.getElementById("search-box"),container=document.getElementById("search-results");searchBox.addEventListener("input",e=>{searchPosts(e.target.value)}),document.addEventListener("click",e=>{!e.target.closest("#search-box")&&!e.target.closest("#search-results")&&container.classList.remove("show")})</script></header><main><div class="ui grid container xo top padding"><div class="computer only row"><div class="eleven wide column"><div class="xo padding top bottom"><div class="ui mini horizontal divided link list"><div class="disabled item">Last edit: 2024-04-22</div><a class="item noelink noul" href=https://github.com//blob/master/posts/%e6%9c%89%e6%b2%a1%e6%9c%89%e5%bf%85%e8%a6%81%e6%89%8b%e5%8a%a8%e5%ae%89%e8%a3%85CUDA.md target=_blank><span data-tooltip="Edit page in GitHub" data-variation=mini data-inverted><i class="fal fa-edit" data-fa-transform="grow-6 right-6"></i>
</span></a><a class="item noelink noul" href=https://github.com//issues/new target=_blank><span data-tooltip="Open GitHub Issue" data-variation=mini data-inverted><i class="fal fa-bug" data-fa-transform="grow-6 right-6"></i>
</span></a><a class="item noelink noul" href=https://github.com//issues/new target=_blank><span data-tooltip="Open Comments Issue in GitHub" data-variation=mini data-inverted><i class="fal fa-comments" data-fa-transform="grow-6 right-6"></i></span></a></div></div><article><h1 class="ui xo margin top without"><div class="ui medium">有没有必要手动安装CUDA</div></h1><p>必须要有的东西是CUDA驱动和CUDA运行时。</p><p>CUDA驱动，一般你就正常安装显卡驱动就有，常打游戏的话电脑上应该有一个nVidia experience，这个软件就是更新驱动的。下载最新的就行。新电脑或新装系统会需要更新这个驱动。安装这个驱动会给你<code>nvidia-smi</code>这个命令。如果这个命令找不到，那就说明没装驱动。</p><p>CUDA运行时，就是下面主要讨论的东西了。</p><ol><li><p>手动安装CUDA和cuDNN（完整）</p><p>比较传统的做法。去nVidia官网下载一个可执行安装文件，一路点下一步，等安装完后你就可以有nvcc这种东西了，一般你能找到的教程不是都让你用<code>nvcc -V</code>来验证安装是否成功嘛。</p><p>安装的东西是最全的，什么visual studio integration啊、nVidia Experience啦、Nsight啦，一不注意就都装上了。</p><p>切换版本比较麻烦，需要自己写脚本改环境变量（<code>CUDA_PATH</code>）
cuDNN的话，去nVidia官网下载，就是一堆文件，不用“安装”。复制粘贴到CUDA目录里就可以了。</p></li><li><p>使用PyTorch（不完整）</p><p><code>PyTorch</code>是自带CUDA和cuDNN的。只要你有nVidia的显卡以及安装了合适的驱动，直接按照PyTorch官网的命令安装PyTorch，然后你就可以写代码运行程序了。虽然nvcc没有，但是丝毫不影响你跑程序。下面这段测试程序是可以通过的。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl> <span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>())</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=p>)</span>  
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>())</span>  
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>current_device</span><span class=p>())</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>version</span><span class=p>())</span>
</span></span><span class=line><span class=cl> <span class=kn>from</span> <span class=nn>torch.backends</span> <span class=kn>import</span> <span class=n>cudnn</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>cudnn</span><span class=o>.</span><span class=n>is_available</span><span class=p>())</span>
</span></span><span class=line><span class=cl> <span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=mf>1.</span><span class=p>)</span>
</span></span><span class=line><span class=cl> <span class=n>a</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>cudnn</span><span class=o>.</span><span class=n>is_acceptable</span><span class=p>(</span><span class=n>a</span><span class=o>.</span><span class=n>cuda</span><span class=p>()))</span>
</span></span></code></pre></div><p>一般是和虚拟环境搭配使用，所以我觉得切换版本也方便。不过既然已经统一为torch实现了，个人认为其实也没什么切换CUDA版本的需求。。</p></li><li><p>虚拟环境内安装CUDA和CUDNN（不完整）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>conda install <span class=nv>cudatoolkit</span><span class=o>==</span>11.8.0 <span class=nv>cudnn</span><span class=o>==</span>8.9.2.26 -c conda-forge
</span></span><span class=line><span class=cl><span class=c1># 或者使用nvidia的源。因为有一些版本在conda-forge上没有，需要两个源都搜一下</span>
</span></span><span class=line><span class=cl>conda install cudatoolkit cudnn -c nvidia
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># cudatoolkit还是cuda-toolkit？ </span>
</span></span><span class=line><span class=cl><span class=c1># cudatoolkit内容少，cuda-toolkit内容全，cuda内容最全</span>
</span></span><span class=line><span class=cl><span class=c1># https://stackoverflow.com/questions/76875734/difference-between-nvidia-cuda-toolkit-and-nvidia-cudatoolkit-packages</span>
</span></span></code></pre></div><p>这样安装好后，你的程序使用这个虚拟环境，也能正常运行。一些非pytorch框架实现的模型就可以这么安装依赖。</p><p>同样的，没有nvcc。原理和pytorch差不多，因为只安装了CUDA的最小部分。</p></li><li><p>虚拟环境内安装CUDA和CUDNN（完整）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 这个cuda相当于是一本书的目录，会给你把一堆东西都装上，就像你直接从官网下载安装一样。</span>
</span></span><span class=line><span class=cl>conda install cuda -c conda-forge
</span></span></code></pre></div><p>烦，我现在搞不清nvidia-container的存在意义了。我觉得这个虚拟环境还能装完整版CUDA运行时的做法已经满足需求了。。。</p></li><li><p>nvidia-container-toolkit（完整）</p><p>从这里可以知道（https://www.cnblogs.com/renoyuan/p/17809212.html）, nvidia-docker + nvidia-container-runtime 已经过时。直接来看nvidia-container-toolkit。</p><p>我觉得只有在你需要完整CUDA，也就是pytoch自带的CUDA和使用conda安装的CUDA提供不了你需要的东西，比如nvcc时，可以尝试这种。基于容器，可以实现完整CUDA runtime的分离。</p></li></ol><p>先这么写着、、</p></article></div><div class="five wide column"><div class="ui attached segment"><table class="ui very basic small compact table"><tbody><tr><td><b>Collection:</b></td><td><a class=noelink href="/browse?q=&idx=diybiosphere&p=0&dFR%5Bcollection%5D%5B0%5D=" target=_blank></a></td></tr><tr class="top aligned"><td><b>Location:</b></td><td><span><a href="http://maps.google.com/?q=" target=_blank></a></span></td></tr></tbody></table></div><div class="ui bottom attached segment"></div></div></div><div class="tablet only row"><div class="nine wide column"><div class="xo padding top bottom"><div class="ui mini horizontal divided link list"><div class="disabled item">Last edit: 2024-04-22</div><a class="item noelink noul" href=https://github.com//blob/master/posts/%e6%9c%89%e6%b2%a1%e6%9c%89%e5%bf%85%e8%a6%81%e6%89%8b%e5%8a%a8%e5%ae%89%e8%a3%85CUDA.md target=_blank><span data-tooltip="Edit page in GitHub" data-variation=mini data-inverted><i class="fal fa-edit" data-fa-transform="grow-6 right-6"></i>
</span></a><a class="item noelink noul" href=https://github.com//issues/new target=_blank><span data-tooltip="Open GitHub Issue" data-variation=mini data-inverted><i class="fal fa-bug" data-fa-transform="grow-6 right-6"></i>
</span></a><a class="item noelink noul" href=https://github.com//issues/new target=_blank><span data-tooltip="Open Comments Issue in GitHub" data-variation=mini data-inverted><i class="fal fa-comments" data-fa-transform="grow-6 right-6"></i></span></a></div></div><article><h1 class="ui xo margin top without"><div class="ui medium">有没有必要手动安装CUDA</div></h1><p>必须要有的东西是CUDA驱动和CUDA运行时。</p><p>CUDA驱动，一般你就正常安装显卡驱动就有，常打游戏的话电脑上应该有一个nVidia experience，这个软件就是更新驱动的。下载最新的就行。新电脑或新装系统会需要更新这个驱动。安装这个驱动会给你<code>nvidia-smi</code>这个命令。如果这个命令找不到，那就说明没装驱动。</p><p>CUDA运行时，就是下面主要讨论的东西了。</p><ol><li><p>手动安装CUDA和cuDNN（完整）</p><p>比较传统的做法。去nVidia官网下载一个可执行安装文件，一路点下一步，等安装完后你就可以有nvcc这种东西了，一般你能找到的教程不是都让你用<code>nvcc -V</code>来验证安装是否成功嘛。</p><p>安装的东西是最全的，什么visual studio integration啊、nVidia Experience啦、Nsight啦，一不注意就都装上了。</p><p>切换版本比较麻烦，需要自己写脚本改环境变量（<code>CUDA_PATH</code>）
cuDNN的话，去nVidia官网下载，就是一堆文件，不用“安装”。复制粘贴到CUDA目录里就可以了。</p></li><li><p>使用PyTorch（不完整）</p><p><code>PyTorch</code>是自带CUDA和cuDNN的。只要你有nVidia的显卡以及安装了合适的驱动，直接按照PyTorch官网的命令安装PyTorch，然后你就可以写代码运行程序了。虽然nvcc没有，但是丝毫不影响你跑程序。下面这段测试程序是可以通过的。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl> <span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>())</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=p>)</span>  
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>())</span>  
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>current_device</span><span class=p>())</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>version</span><span class=p>())</span>
</span></span><span class=line><span class=cl> <span class=kn>from</span> <span class=nn>torch.backends</span> <span class=kn>import</span> <span class=n>cudnn</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>cudnn</span><span class=o>.</span><span class=n>is_available</span><span class=p>())</span>
</span></span><span class=line><span class=cl> <span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=mf>1.</span><span class=p>)</span>
</span></span><span class=line><span class=cl> <span class=n>a</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>cudnn</span><span class=o>.</span><span class=n>is_acceptable</span><span class=p>(</span><span class=n>a</span><span class=o>.</span><span class=n>cuda</span><span class=p>()))</span>
</span></span></code></pre></div><p>一般是和虚拟环境搭配使用，所以我觉得切换版本也方便。不过既然已经统一为torch实现了，个人认为其实也没什么切换CUDA版本的需求。。</p></li><li><p>虚拟环境内安装CUDA和CUDNN（不完整）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>conda install <span class=nv>cudatoolkit</span><span class=o>==</span>11.8.0 <span class=nv>cudnn</span><span class=o>==</span>8.9.2.26 -c conda-forge
</span></span><span class=line><span class=cl><span class=c1># 或者使用nvidia的源。因为有一些版本在conda-forge上没有，需要两个源都搜一下</span>
</span></span><span class=line><span class=cl>conda install cudatoolkit cudnn -c nvidia
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># cudatoolkit还是cuda-toolkit？ </span>
</span></span><span class=line><span class=cl><span class=c1># cudatoolkit内容少，cuda-toolkit内容全，cuda内容最全</span>
</span></span><span class=line><span class=cl><span class=c1># https://stackoverflow.com/questions/76875734/difference-between-nvidia-cuda-toolkit-and-nvidia-cudatoolkit-packages</span>
</span></span></code></pre></div><p>这样安装好后，你的程序使用这个虚拟环境，也能正常运行。一些非pytorch框架实现的模型就可以这么安装依赖。</p><p>同样的，没有nvcc。原理和pytorch差不多，因为只安装了CUDA的最小部分。</p></li><li><p>虚拟环境内安装CUDA和CUDNN（完整）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 这个cuda相当于是一本书的目录，会给你把一堆东西都装上，就像你直接从官网下载安装一样。</span>
</span></span><span class=line><span class=cl>conda install cuda -c conda-forge
</span></span></code></pre></div><p>烦，我现在搞不清nvidia-container的存在意义了。我觉得这个虚拟环境还能装完整版CUDA运行时的做法已经满足需求了。。。</p></li><li><p>nvidia-container-toolkit（完整）</p><p>从这里可以知道（https://www.cnblogs.com/renoyuan/p/17809212.html）, nvidia-docker + nvidia-container-runtime 已经过时。直接来看nvidia-container-toolkit。</p><p>我觉得只有在你需要完整CUDA，也就是pytoch自带的CUDA和使用conda安装的CUDA提供不了你需要的东西，比如nvcc时，可以尝试这种。基于容器，可以实现完整CUDA runtime的分离。</p></li></ol><p>先这么写着、、</p></article></div><div class="seven wide column"><div class="ui attached segment"><table class="ui very basic small compact table"><tbody><tr><td><b>Collection:</b></td><td><a class=noelink href="/browse?q=&idx=diybiosphere&p=0&dFR%5Bcollection%5D%5B0%5D=" target=_blank></a></td></tr><tr class="top aligned"><td><b>Location:</b></td><td><span><a href="http://maps.google.com/?q=" target=_blank></a></span></td></tr></tbody></table></div><div class="ui bottom attached segment"></div></div></div><div class="mobile only row"><div class="sixteen wide column"><div class="ui attached segment"><table class="ui very basic small compact table"><tbody><tr><td><b>Collection:</b></td><td><a class=noelink href="/browse?q=&idx=diybiosphere&p=0&dFR%5Bcollection%5D%5B0%5D=" target=_blank></a></td></tr><tr class="top aligned"><td><b>Location:</b></td><td><span><a href="http://maps.google.com/?q=" target=_blank></a></span></td></tr></tbody></table></div><div class="ui bottom attached segment"></div></div><div class="sixteen wide column xo top padding fourfold"><div class="xo padding top bottom"><div class="ui mini horizontal divided link list"><div class="disabled item">Last edit: 2024-04-22</div><a class="item noelink noul" href=https://github.com//blob/master/posts/%e6%9c%89%e6%b2%a1%e6%9c%89%e5%bf%85%e8%a6%81%e6%89%8b%e5%8a%a8%e5%ae%89%e8%a3%85CUDA.md target=_blank><span data-tooltip="Edit page in GitHub" data-variation=mini data-inverted><i class="fal fa-edit" data-fa-transform="grow-6 right-6"></i>
</span></a><a class="item noelink noul" href=https://github.com//issues/new target=_blank><span data-tooltip="Open GitHub Issue" data-variation=mini data-inverted><i class="fal fa-bug" data-fa-transform="grow-6 right-6"></i>
</span></a><a class="item noelink noul" href=https://github.com//issues/new target=_blank><span data-tooltip="Open Comments Issue in GitHub" data-variation=mini data-inverted><i class="fal fa-comments" data-fa-transform="grow-6 right-6"></i></span></a></div></div><article><h1 class="ui xo margin top without"><div class="ui medium">有没有必要手动安装CUDA</div></h1><p>必须要有的东西是CUDA驱动和CUDA运行时。</p><p>CUDA驱动，一般你就正常安装显卡驱动就有，常打游戏的话电脑上应该有一个nVidia experience，这个软件就是更新驱动的。下载最新的就行。新电脑或新装系统会需要更新这个驱动。安装这个驱动会给你<code>nvidia-smi</code>这个命令。如果这个命令找不到，那就说明没装驱动。</p><p>CUDA运行时，就是下面主要讨论的东西了。</p><ol><li><p>手动安装CUDA和cuDNN（完整）</p><p>比较传统的做法。去nVidia官网下载一个可执行安装文件，一路点下一步，等安装完后你就可以有nvcc这种东西了，一般你能找到的教程不是都让你用<code>nvcc -V</code>来验证安装是否成功嘛。</p><p>安装的东西是最全的，什么visual studio integration啊、nVidia Experience啦、Nsight啦，一不注意就都装上了。</p><p>切换版本比较麻烦，需要自己写脚本改环境变量（<code>CUDA_PATH</code>）
cuDNN的话，去nVidia官网下载，就是一堆文件，不用“安装”。复制粘贴到CUDA目录里就可以了。</p></li><li><p>使用PyTorch（不完整）</p><p><code>PyTorch</code>是自带CUDA和cuDNN的。只要你有nVidia的显卡以及安装了合适的驱动，直接按照PyTorch官网的命令安装PyTorch，然后你就可以写代码运行程序了。虽然nvcc没有，但是丝毫不影响你跑程序。下面这段测试程序是可以通过的。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl> <span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>())</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=p>)</span>  
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>device_count</span><span class=p>())</span>  
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>current_device</span><span class=p>())</span> 
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>backends</span><span class=o>.</span><span class=n>cudnn</span><span class=o>.</span><span class=n>version</span><span class=p>())</span>
</span></span><span class=line><span class=cl> <span class=kn>from</span> <span class=nn>torch.backends</span> <span class=kn>import</span> <span class=n>cudnn</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>cudnn</span><span class=o>.</span><span class=n>is_available</span><span class=p>())</span>
</span></span><span class=line><span class=cl> <span class=n>a</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=mf>1.</span><span class=p>)</span>
</span></span><span class=line><span class=cl> <span class=n>a</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl> <span class=nb>print</span><span class=p>(</span><span class=n>cudnn</span><span class=o>.</span><span class=n>is_acceptable</span><span class=p>(</span><span class=n>a</span><span class=o>.</span><span class=n>cuda</span><span class=p>()))</span>
</span></span></code></pre></div><p>一般是和虚拟环境搭配使用，所以我觉得切换版本也方便。不过既然已经统一为torch实现了，个人认为其实也没什么切换CUDA版本的需求。。</p></li><li><p>虚拟环境内安装CUDA和CUDNN（不完整）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>conda install <span class=nv>cudatoolkit</span><span class=o>==</span>11.8.0 <span class=nv>cudnn</span><span class=o>==</span>8.9.2.26 -c conda-forge
</span></span><span class=line><span class=cl><span class=c1># 或者使用nvidia的源。因为有一些版本在conda-forge上没有，需要两个源都搜一下</span>
</span></span><span class=line><span class=cl>conda install cudatoolkit cudnn -c nvidia
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># cudatoolkit还是cuda-toolkit？ </span>
</span></span><span class=line><span class=cl><span class=c1># cudatoolkit内容少，cuda-toolkit内容全，cuda内容最全</span>
</span></span><span class=line><span class=cl><span class=c1># https://stackoverflow.com/questions/76875734/difference-between-nvidia-cuda-toolkit-and-nvidia-cudatoolkit-packages</span>
</span></span></code></pre></div><p>这样安装好后，你的程序使用这个虚拟环境，也能正常运行。一些非pytorch框架实现的模型就可以这么安装依赖。</p><p>同样的，没有nvcc。原理和pytorch差不多，因为只安装了CUDA的最小部分。</p></li><li><p>虚拟环境内安装CUDA和CUDNN（完整）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 这个cuda相当于是一本书的目录，会给你把一堆东西都装上，就像你直接从官网下载安装一样。</span>
</span></span><span class=line><span class=cl>conda install cuda -c conda-forge
</span></span></code></pre></div><p>烦，我现在搞不清nvidia-container的存在意义了。我觉得这个虚拟环境还能装完整版CUDA运行时的做法已经满足需求了。。。</p></li><li><p>nvidia-container-toolkit（完整）</p><p>从这里可以知道（https://www.cnblogs.com/renoyuan/p/17809212.html）, nvidia-docker + nvidia-container-runtime 已经过时。直接来看nvidia-container-toolkit。</p><p>我觉得只有在你需要完整CUDA，也就是pytoch自带的CUDA和使用conda安装的CUDA提供不了你需要的东西，比如nvcc时，可以尝试这种。基于容器，可以实现完整CUDA runtime的分离。</p></li></ol><p>先这么写着、、</p></article></div></div></div><div class="ui grid container xo top padding"><section class="xo margin top fourfold"><h3 class="ui horizontal divider header"><i class="far fa-comments"></i> Comments</h3><a target=_blank href=https://github.com//issues/new><div class="ui basic submit mini button"><i class="fal fa-comment"></i> Open Comments Issue in GitHub</div></a></section></div><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/datejs/1.0/date.min.js></script><script type=text/javascript>function loadComments(e){for(var n,s,o,i,a,r,c,t=0;t<e.length;t++)s=e[t].user.login,o="https://www.github.com/"+e[t].user.login,c=e[t].user.type,n="https://github.com//issues/#issuecomment-"+e[t].url.substring(e[t].url.lastIndexOf("/")+1),i=e[t].body_html,a=e[t].user.avatar_url,r=Date.parse(e[t].created_at).toString("yyyy-MM-dd HH:mm"),$("#comments").append(`<div class='comment'><a class='avatar'><img src="`+a+`"></a><div class='content'><a class='author' target='_blank' href="`+o+'">'+s+"</a><div class='metadata'><div class='date'>"+r+"</div></div><div class='text'>"+i+`</div></div><div class='actions'><a target='_blank' href="`+n+`" class='reply'><i class='far fa-reply'></i> Reply</a><a target='_blank' href="`+n+`" class='reply'><i class='far fa-smile'></i> React</a></div></div></div>`)}</script></main><footer><footer class="xo top margin sixfold"><div class="ui container center aligned grid xo top bottom padding"><div class=row><div class="sixteen wide column"><div class="ui small horizontal divided link list"><a class=item href=https://github.com/DIYbiosphere/sphere>This site's theme is powered by DIYbiosphere under CC0.</a></div></div></div></div></footer></footer></body></html>